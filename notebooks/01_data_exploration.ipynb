{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1625289c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root (expected): /home/mohamed/trainings/RL_project\n",
      "Src path (expected): /home/mohamed/trainings/RL_project/src\n"
     ]
    }
   ],
   "source": [
    "# notebooks/recsys_collaborative_filtering.ipynb\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 0. Setup and Imports\n",
    "# ---------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix # For creating sparse utility matrices\n",
    "from sklearn.metrics.pairwise import cosine_similarity # For item-item or user-user similarity\n",
    "from sklearn.neighbors import NearestNeighbors # For KNN-based CF\n",
    "\n",
    "# For potential matrix factorization (example using Surprise or implicit)\n",
    "# from surprise import Dataset, Reader, SVD, NMF # Example: pip install scikit-surprise\n",
    "# import implicit # Example: pip install implicit\n",
    "\n",
    "# Adjust Python path to import from src\n",
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Import your DataLoader and mock_data if needed for initial data\n",
    "from data_management.data_loader import DataLoader\n",
    "from data_management.mock_data import create_mock_data\n",
    "\n",
    "# Configure logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='[%(asctime)s][%(levelname)s] %(message)s')\n",
    "log = logging.getLogger()\n",
    "\n",
    "# Pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(f\"Project root (expected): {project_root}\")\n",
    "print(f\"Src path (expected): {src_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a7ff1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-06-02 11:54:25,873][INFO] Generating SYNTHETIC data for RecSys exploration...\n",
      "[2025-06-02 11:54:25,874][INFO] Generating mock data (seed=42, type='training', n_assets=100, n_users=50).\n",
      "[2025-06-02 11:54:26,116][INFO] Mock data generation complete.\n",
      "[2025-06-02 11:54:26,124][INFO] Generated synthetic data: 50 users, 100 assets, 300 transactions.\n",
      "[2025-06-02 11:54:26,127][INFO] Total 'buy' transactions: 162\n",
      "[2025-06-02 11:54:26,128][INFO] Unique customers in buy transactions: 48\n",
      "[2025-06-02 11:54:26,129][INFO] Unique assets in buy transactions: 83\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 1. Load Data\n",
    "# ---------------------------------------------------------------------------\n",
    "USE_REAL_DATA_FOR_RECSYS = False # Set to True to use your real data, False for mock\n",
    "TOP_N_CUSTOMERS_RECSYS = 100   # How many customers to use if real data is chosen\n",
    "\n",
    "if USE_REAL_DATA_FOR_RECSYS:\n",
    "    log.info(\"Loading REAL data for RecSys exploration...\")\n",
    "    try:\n",
    "        data_loader = DataLoader() # Assuming default paths are correct or configured\n",
    "        data_loader._load_raw_data()\n",
    "        \n",
    "        raw_customers_df = data_loader._raw_customers\n",
    "        raw_assets_df = data_loader._raw_assets # We might not use all asset features for basic CF\n",
    "        raw_transactions_df = data_loader._raw_transactions\n",
    "\n",
    "        if TOP_N_CUSTOMERS_RECSYS is not None and raw_transactions_df is not None and not raw_transactions_df.empty:\n",
    "            customer_activity = raw_transactions_df['customerID'].value_counts()\n",
    "            if TOP_N_CUSTOMERS_RECSYS >= len(customer_activity):\n",
    "                top_customer_ids = customer_activity.index.tolist()\n",
    "            else:\n",
    "                top_customer_ids = customer_activity.head(TOP_N_CUSTOMERS_RECSYS).index.tolist()\n",
    "            \n",
    "            customers_df = raw_customers_df[raw_customers_df['customerID'].isin(top_customer_ids)].copy()\n",
    "            transactions_df = raw_transactions_df[raw_transactions_df['customerID'].isin(top_customer_ids)].copy()\n",
    "            assets_df = raw_assets_df # Keep all assets\n",
    "        else:\n",
    "            customers_df = raw_customers_df\n",
    "            transactions_df = raw_transactions_df\n",
    "            assets_df = raw_assets_df\n",
    "        log.info(f\"Using {len(customers_df)} customers and their {len(transactions_df)} transactions.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        log.error(f\"Error loading real data: {e}. Falling back to synthetic.\", exc_info=True)\n",
    "        USE_SYNTHETIC_DATA_FOR_RECSYS = True # Fallback to synthetic\n",
    "else:\n",
    "    USE_SYNTHETIC_DATA_FOR_RECSYS = True # Ensure this flag is set if above fails or is false\n",
    "\n",
    "if USE_SYNTHETIC_DATA_FOR_RECSYS:\n",
    "    log.info(\"Generating SYNTHETIC data for RecSys exploration...\")\n",
    "    SYNTHETIC_N_USERS = 50\n",
    "    SYNTHETIC_N_ASSETS = 100\n",
    "    SYNTHETIC_TOTAL_DAYS = 365 * 3\n",
    "    customers_df, assets_df, _, transactions_df = create_mock_data( # prices_df not strictly needed for basic CF\n",
    "        seed=42, n_users=SYNTHETIC_N_USERS, n_assets=SYNTHETIC_N_ASSETS, total_days=SYNTHETIC_TOTAL_DAYS\n",
    "    )\n",
    "    log.info(f\"Generated synthetic data: {len(customers_df)} users, {len(assets_df)} assets, {len(transactions_df)} transactions.\")\n",
    "\n",
    "# Basic cleaning\n",
    "transactions_df = transactions_df[transactions_df['totalValue'] > 0].copy()\n",
    "transactions_df['transactionType'] = transactions_df['transactionType'].str.lower()\n",
    "\n",
    "# We are interested in \"Buy\" transactions as positive interactions\n",
    "buy_transactions_df = transactions_df[transactions_df['transactionType'] == 'buy'].copy()\n",
    "\n",
    "log.info(f\"Total 'buy' transactions: {len(buy_transactions_df)}\")\n",
    "log.info(f\"Unique customers in buy transactions: {buy_transactions_df['customerID'].nunique()}\")\n",
    "log.info(f\"Unique assets in buy transactions: {buy_transactions_df['ISIN'].nunique()}\")\n",
    "\n",
    "if buy_transactions_df.empty:\n",
    "    raise ValueError(\"No 'buy' transactions found. Cannot proceed with collaborative filtering.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f971caa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-06-02 11:54:26,143][INFO] User-Item interaction counts (head):\n",
      "[2025-06-02 11:54:26,149][INFO] Utility matrix shape: (48, 83) (Users x Assets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  customerID         ISIN  buy_count\n",
      "0        TC1  ISIN_MOCK_b          1\n",
      "1        TC1  ISIN_MOCK_q          1\n",
      "2        TC1  ISIN_MOCK_y          1\n",
      "3        TC1  ISIN_MOCK_          1\n",
      "4        TC1  ISIN_MOCK_          1\n",
      "ISIN        ISIN_MOCK_A  ISIN_MOCK_B  ISIN_MOCK_C  ISIN_MOCK_D  ISIN_MOCK_E  ISIN_MOCK_F  ISIN_MOCK_H  ISIN_MOCK_I  ISIN_MOCK_K  ISIN_MOCK_L  ISIN_MOCK_M  ISIN_MOCK_O  ISIN_MOCK_P  ISIN_MOCK_R  ISIN_MOCK_S  ISIN_MOCK_T  ISIN_MOCK_U  ISIN_MOCK_X  ISIN_MOCK_Y  ISIN_MOCK_Z  ISIN_MOCK_[  ISIN_MOCK_\\  ISIN_MOCK_]  ISIN_MOCK__  ISIN_MOCK_`  ISIN_MOCK_a  ISIN_MOCK_b  ISIN_MOCK_c  ISIN_MOCK_e  ISIN_MOCK_g  ISIN_MOCK_h  ISIN_MOCK_i  ISIN_MOCK_j  ISIN_MOCK_k  ISIN_MOCK_l  ISIN_MOCK_m  ISIN_MOCK_o  ISIN_MOCK_p  ISIN_MOCK_q  ISIN_MOCK_r  ISIN_MOCK_s  ISIN_MOCK_t  ISIN_MOCK_u  ISIN_MOCK_v  ISIN_MOCK_x  ISIN_MOCK_y  ISIN_MOCK_{  ISIN_MOCK_|  ISIN_MOCK_}  ISIN_MOCK_~  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  \\\n",
      "customerID                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "TC1                 0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          1.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          1.0          0.0          0.0          0.0          0.0          0.0          0.0          1.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          1.0          1.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          1.0          0.0          0.0          0.0   \n",
      "TC10                0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          1.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          1.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          1.0          0.0          0.0          0.0          0.0          1.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0   \n",
      "TC11                0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0   \n",
      "TC12                0.0          0.0          0.0          0.0          1.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          1.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          1.0   \n",
      "TC13                0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          1.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          1.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0          1.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0   \n",
      "\n",
      "ISIN        ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_  ISIN_MOCK_   ISIN_MOCK_¡  ISIN_MOCK_¢  ISIN_MOCK_£  ISIN_MOCK_¤  \n",
      "customerID                                                                                                          \n",
      "TC1                 0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0  \n",
      "TC10                0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0  \n",
      "TC11                0.0          0.0          0.0          0.0          0.0          0.0          1.0          0.0  \n",
      "TC12                0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0  \n",
      "TC13                0.0          0.0          0.0          0.0          0.0          0.0          0.0          0.0  \n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 2. User-Item Interaction Matrix / Graph Conceptualization\n",
    "# ---------------------------------------------------------------------------\n",
    "# For collaborative filtering, we often start with a user-item interaction matrix.\n",
    "# Rows: Users, Columns: Assets\n",
    "# Values: Implicit feedback (e.g., number of buys, total value bought) or binary (1 if bought, 0 otherwise)\n",
    "\n",
    "# Let's use \"number of buy transactions\" as the interaction strength for now.\n",
    "user_item_interaction_counts = buy_transactions_df.groupby(['customerID', 'ISIN']).size().reset_index(name='buy_count')\n",
    "\n",
    "log.info(\"User-Item interaction counts (head):\")\n",
    "print(user_item_interaction_counts.head())\n",
    "\n",
    "# Create a pivot table for the utility matrix\n",
    "try:\n",
    "    utility_matrix_df = user_item_interaction_counts.pivot(\n",
    "        index='customerID',\n",
    "        columns='ISIN',\n",
    "        values='buy_count'\n",
    "    ).fillna(0) # Fill NaN (no interaction) with 0\n",
    "except Exception as e:\n",
    "    log.error(f\"Error creating pivot table, possibly due to duplicate (customerID, ISIN) entries if not aggregated first: {e}\")\n",
    "    # If groupby wasn't done first, duplicates would cause an error here.\n",
    "    # But user_item_interaction_counts should have unique (customerID, ISIN) due to groupby.\n",
    "    raise\n",
    "\n",
    "log.info(f\"Utility matrix shape: {utility_matrix_df.shape} (Users x Assets)\")\n",
    "print(utility_matrix_df.head())\n",
    "\n",
    "# Convert to a sparse matrix for efficiency, especially if large\n",
    "utility_matrix_sparse = csr_matrix(utility_matrix_df.values)\n",
    "# Keep mappings for user/item indices\n",
    "user_id_to_idx = {user_id: i for i, user_id in enumerate(utility_matrix_df.index)}\n",
    "item_isin_to_idx = {isin: i for i, isin in enumerate(utility_matrix_df.columns)}\n",
    "idx_to_user_id = {i: user_id for user_id, i in user_id_to_idx.items()}\n",
    "idx_to_item_isin = {i: isin for isin, i in item_isin_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "251e8406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-06-02 11:54:26,217][INFO] Implementing Item-Based Collaborative Filtering...\n",
      "[2025-06-02 11:54:26,221][INFO] Item-Item Cosine Similarity Matrix (portion):\n",
      "[2025-06-02 11:54:26,228][INFO] \n",
      "Getting item-based recommendations for customer: TC1\n",
      "[2025-06-02 11:54:26,234][INFO] Recommendations: ['ISIN_MOCK__', 'ISIN_MOCK_\\x80', 'ISIN_MOCK_`', 'ISIN_MOCK_k', 'ISIN_MOCK_\\x89']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISIN         ISIN_MOCK_A  ISIN_MOCK_B  ISIN_MOCK_C  ISIN_MOCK_D  ISIN_MOCK_E\n",
      "ISIN                                                                        \n",
      "ISIN_MOCK_A          1.0          0.0          0.0          0.0          0.0\n",
      "ISIN_MOCK_B          0.0          1.0          0.0          0.0          0.0\n",
      "ISIN_MOCK_C          0.0          0.0          1.0          0.0          0.0\n",
      "ISIN_MOCK_D          0.0          0.0          0.0          1.0          0.0\n",
      "ISIN_MOCK_E          0.0          0.0          0.0          0.0          1.0\n",
      "           ISIN  VolatilityQuartile\n",
      "30  ISIN_MOCK__                   2\n",
      "31  ISIN_MOCK_`                   1\n",
      "42  ISIN_MOCK_k                   3\n",
      "63  ISIN_MOCK_                   4\n",
      "72  ISIN_MOCK_                   2\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 3. Item-Based Collaborative Filtering (Example using KNN similarity)\n",
    "# ---------------------------------------------------------------------------\n",
    "log.info(\"Implementing Item-Based Collaborative Filtering...\")\n",
    "\n",
    "# Calculate item-item similarity (e.g., cosine similarity on the transpose of utility matrix)\n",
    "# utility_matrix_df.T gives Items x Users\n",
    "item_similarity_matrix = cosine_similarity(utility_matrix_df.T) # Item-Item similarity\n",
    "# item_similarity_matrix is a NumPy array where item_similarity_matrix[i, j] is similarity between item i and item j\n",
    "\n",
    "# Convert to DataFrame for easier lookup\n",
    "item_similarity_df = pd.DataFrame(item_similarity_matrix,\n",
    "                                  index=utility_matrix_df.columns,\n",
    "                                  columns=utility_matrix_df.columns)\n",
    "\n",
    "log.info(\"Item-Item Cosine Similarity Matrix (portion):\")\n",
    "print(item_similarity_df.iloc[:5, :5])\n",
    "\n",
    "def get_item_based_recommendations(customer_id_target: str,\n",
    "                                   utility_matrix: pd.DataFrame,\n",
    "                                   item_similarity: pd.DataFrame,\n",
    "                                   k_similar_items: int = 5,\n",
    "                                   n_recommendations: int = 5):\n",
    "    \"\"\"\n",
    "    Generates item-based CF recommendations for a user.\n",
    "    1. Find items the user has interacted with.\n",
    "    2. For each interacted item, find its k most similar items.\n",
    "    3. Aggregate similarity scores for candidate items (not yet interacted by user).\n",
    "    4. Recommend top N.\n",
    "    \"\"\"\n",
    "    if customer_id_target not in utility_matrix.index:\n",
    "        log.warning(f\"Customer {customer_id_target} not found in utility matrix.\")\n",
    "        return []\n",
    "\n",
    "    user_interactions = utility_matrix.loc[customer_id_target]\n",
    "    interacted_items = user_interactions[user_interactions > 0].index.tolist() # ISINs\n",
    "    \n",
    "    if not interacted_items:\n",
    "        log.info(f\"Customer {customer_id_target} has no interactions. Cannot provide item-based recommendations.\")\n",
    "        return []\n",
    "\n",
    "    candidate_scores = {} # Dict to store potential recommendations and their scores\n",
    "\n",
    "    for item_isin_hist in interacted_items:\n",
    "        if item_isin_hist not in item_similarity.index: # Should not happen if matrix is consistent\n",
    "            continue\n",
    "        # Get similarity scores of this historical item with all other items\n",
    "        similar_to_item_hist = item_similarity[item_isin_hist].sort_values(ascending=False)\n",
    "        \n",
    "        for similar_item_isin, similarity_score in similar_to_item_hist.iloc[1:k_similar_items+1].items(): # Skip itself (sim=1)\n",
    "            if similar_item_isin not in interacted_items: # Don't recommend items already interacted with\n",
    "                candidate_scores[similar_item_isin] = candidate_scores.get(similar_item_isin, 0) + similarity_score\n",
    "    \n",
    "    # Sort candidates by score\n",
    "    sorted_candidates = sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    recommendations = [item[0] for item in sorted_candidates[:n_recommendations]]\n",
    "    return recommendations\n",
    "\n",
    "# Example: Get recommendations for a user\n",
    "if not customers_df.empty:\n",
    "    sample_customer_id = customers_df['customerID'].iloc[0]\n",
    "    log.info(f\"\\nGetting item-based recommendations for customer: {sample_customer_id}\")\n",
    "    recommendations = get_item_based_recommendations(sample_customer_id, utility_matrix_df, item_similarity_df)\n",
    "    if recommendations:\n",
    "        log.info(f\"Recommendations: {recommendations}\")\n",
    "        # You could look up asset names from assets_df here\n",
    "        recs_with_names = assets_df[assets_df['ISIN'].isin(recommendations)][['ISIN', 'VolatilityQuartile']] # Add AssetName if you have it\n",
    "        print(recs_with_names)\n",
    "    else:\n",
    "        log.info(\"No recommendations generated (e.g., user has no history or no similar items found).\")\n",
    "else:\n",
    "    log.warning(\"No customers loaded, cannot get recommendations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6be98a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-06-02 11:54:26,255][INFO] Implementing Item-Based Collaborative Filtering...\n",
      "[2025-06-02 11:54:26,258][INFO] Item-Item Cosine Similarity Matrix (portion):\n",
      "[2025-06-02 11:54:26,262][INFO] \n",
      "Getting item-based recommendations for customer: TC1\n",
      "[2025-06-02 11:54:26,272][INFO] Recommendations: ['ISIN_MOCK__', 'ISIN_MOCK_\\x80', 'ISIN_MOCK_`', 'ISIN_MOCK_k', 'ISIN_MOCK_\\x89']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISIN         ISIN_MOCK_A  ISIN_MOCK_B  ISIN_MOCK_C  ISIN_MOCK_D  ISIN_MOCK_E\n",
      "ISIN                                                                        \n",
      "ISIN_MOCK_A          1.0          0.0          0.0          0.0          0.0\n",
      "ISIN_MOCK_B          0.0          1.0          0.0          0.0          0.0\n",
      "ISIN_MOCK_C          0.0          0.0          1.0          0.0          0.0\n",
      "ISIN_MOCK_D          0.0          0.0          0.0          1.0          0.0\n",
      "ISIN_MOCK_E          0.0          0.0          0.0          0.0          1.0\n",
      "Recommended Assets Details:\n",
      "           ISIN  VolatilityQuartile\n",
      "30  ISIN_MOCK__                   2\n",
      "31  ISIN_MOCK_`                   1\n",
      "42  ISIN_MOCK_k                   3\n",
      "63  ISIN_MOCK_                   4\n",
      "72  ISIN_MOCK_                   2\n"
     ]
    }
   ],
   "source": [
    "# CELL 4 MODIFIED FOR DEBUGGING\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3. Item-Based Collaborative Filtering (Example using KNN similarity)\n",
    "# ---------------------------------------------------------------------------\n",
    "log.info(\"Implementing Item-Based Collaborative Filtering...\")\n",
    "\n",
    "# Calculate item-item similarity\n",
    "if utility_matrix_df.shape[1] == 0: # No items/columns\n",
    "    log.error(\"Utility matrix has no items (columns). Cannot compute item similarity.\")\n",
    "    item_similarity_df = pd.DataFrame() # Empty DataFrame\n",
    "else:\n",
    "    item_similarity_matrix = cosine_similarity(utility_matrix_df.T)\n",
    "    item_similarity_df = pd.DataFrame(item_similarity_matrix,\n",
    "                                      index=utility_matrix_df.columns,\n",
    "                                      columns=utility_matrix_df.columns)\n",
    "    log.info(\"Item-Item Cosine Similarity Matrix (portion):\")\n",
    "    print(item_similarity_df.iloc[:min(5, item_similarity_df.shape[0]), :min(5, item_similarity_df.shape[1])])\n",
    "\n",
    "\n",
    "def get_item_based_recommendations(customer_id_target: str,\n",
    "                                   utility_matrix: pd.DataFrame,\n",
    "                                   item_similarity: pd.DataFrame,\n",
    "                                   k_similar_items: int = 5,\n",
    "                                   n_recommendations: int = 5):\n",
    "    log.debug(f\"Attempting item-based recommendations for: {customer_id_target}\")\n",
    "    if customer_id_target not in utility_matrix.index:\n",
    "        log.warning(f\"Customer {customer_id_target} not found in utility matrix.\")\n",
    "        return []\n",
    "\n",
    "    user_interactions = utility_matrix.loc[customer_id_target]\n",
    "    interacted_items = user_interactions[user_interactions > 0].index.tolist()\n",
    "    log.debug(f\"Customer {customer_id_target} has interacted with items: {interacted_items}\")\n",
    "    \n",
    "    if not interacted_items:\n",
    "        log.info(f\"Customer {customer_id_target} has no interactions. No item-based recommendations.\")\n",
    "        return []\n",
    "    \n",
    "    if item_similarity.empty:\n",
    "        log.warning(\"Item similarity matrix is empty. Cannot generate recommendations.\")\n",
    "        return []\n",
    "\n",
    "    candidate_scores = {}\n",
    "\n",
    "    for item_isin_hist in interacted_items:\n",
    "        log.debug(f\"  Processing historical item: {item_isin_hist}\")\n",
    "        if item_isin_hist not in item_similarity.index:\n",
    "            log.warning(f\"    Historical item {item_isin_hist} not found in item_similarity matrix index. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        similar_to_item_hist = item_similarity[item_isin_hist].sort_values(ascending=False)\n",
    "        log.debug(f\"    Top similar items to {item_isin_hist} (before filtering):\\n{similar_to_item_hist.head(k_similar_items + 2)}\")\n",
    "        \n",
    "        # Iterate over top k_similar_items, skipping the item itself\n",
    "        for similar_item_isin, similarity_score in similar_to_item_hist.iloc[1:k_similar_items+1].items():\n",
    "            log.debug(f\"      Considering similar item: {similar_item_isin} with score {similarity_score:.4f}\")\n",
    "            if similar_item_isin not in interacted_items:\n",
    "                candidate_scores[similar_item_isin] = candidate_scores.get(similar_item_isin, 0) + similarity_score\n",
    "                log.debug(f\"        Added/Updated score for candidate {similar_item_isin}: {candidate_scores[similar_item_isin]:.4f}\")\n",
    "            else:\n",
    "                log.debug(f\"        Skipping {similar_item_isin} as it was already interacted with by the user.\")\n",
    "    \n",
    "    if not candidate_scores:\n",
    "        log.info(f\"No new candidate items found for {customer_id_target} after considering similar items.\")\n",
    "        return []\n",
    "\n",
    "    sorted_candidates = sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    log.debug(f\"  Sorted candidate scores: {sorted_candidates[:n_recommendations+5]}\")\n",
    "    \n",
    "    recommendations = [item[0] for item in sorted_candidates[:n_recommendations]]\n",
    "    return recommendations\n",
    "\n",
    "# Example: Get recommendations for a user\n",
    "if not customers_df.empty and not utility_matrix_df.empty: # Ensure utility_matrix_df is not empty\n",
    "    sample_customer_id = customers_df['customerID'].iloc[0]\n",
    "    if sample_customer_id in utility_matrix_df.index: # Check if sample customer is in utility matrix\n",
    "        log.info(f\"\\nGetting item-based recommendations for customer: {sample_customer_id}\")\n",
    "        recommendations = get_item_based_recommendations(sample_customer_id, utility_matrix_df, item_similarity_df)\n",
    "        if recommendations:\n",
    "            log.info(f\"Recommendations: {recommendations}\")\n",
    "            recs_with_names = assets_df[assets_df['ISIN'].isin(recommendations)][['ISIN', 'VolatilityQuartile']]\n",
    "            print(\"Recommended Assets Details:\")\n",
    "            print(recs_with_names)\n",
    "        else:\n",
    "            log.info(\"No recommendations generated (e.g., user has no history or no new similar items found).\")\n",
    "    else:\n",
    "        log.warning(f\"Sample customer {sample_customer_id} not found in the utility matrix. Utility matrix rows: {utility_matrix_df.index.tolist()[:5]}\")\n",
    "else:\n",
    "    log.warning(\"Customers DataFrame or Utility Matrix is empty, cannot get recommendations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "09c9ffe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-06-02 11:54:26,295][INFO] \n",
      "--- Attempting 3D Graph Visualization with VisPy ---\n",
      "[2025-06-02 11:54:26,299][INFO] VisPy: Sample user for explanation: TC37\n",
      "[2025-06-02 11:54:26,305][INFO] VisPy: Recommendations for TC37 to explain: ['ISIN_MOCK_y', 'ISIN_MOCK_R']\n",
      "[2025-06-02 11:54:26,309][INFO] VisPy: NetworkX graph created: 25 nodes, 18 edges for vis.\n",
      "[2025-06-02 11:54:26,316][INFO] VisPy: 3D layout calculated.\n",
      "WARNING: could not determine DPI\n",
      "[2025-06-02 11:54:26,361][WARNING] could not determine DPI\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not import backend \"jupyter_rfb\":\nThe jupyter_rfb backend relies on a the jupyter_rfb library: ``pip install jupyter_rfb``",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 128\u001b[0m\n\u001b[1;32m    124\u001b[0m     node_pos_array_vp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node_pos_array_vp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# --- Create VisPy Scene ---\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     canvas \u001b[38;5;241m=\u001b[39m \u001b[43mscene\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSceneCanvas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minteractive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbgcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwhite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     view \u001b[38;5;241m=\u001b[39m canvas\u001b[38;5;241m.\u001b[39mcentral_widget\u001b[38;5;241m.\u001b[39madd_view()\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# Camera\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/reinforcement_project/lib/python3.13/site-packages/vispy/scene/canvas.py:135\u001b[0m, in \u001b[0;36mSceneCanvas.__init__\u001b[0;34m(self, title, size, position, show, autoswap, app, create_native, vsync, resizable, decorate, fullscreen, config, shared, keys, parent, dpi, always_on_top, px_scale, bgcolor)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Set to True to enable sending mouse events even when no button is\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# pressed. Disabled by default because it is very expensive. Also\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# private for now because this behavior / API needs more thought.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_hover_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSceneCanvas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoswap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_native\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvsync\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresizable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfullscreen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43malways_on_top\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpx_scale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevents\u001b[38;5;241m.\u001b[39mmouse_press\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_mouse_event)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevents\u001b[38;5;241m.\u001b[39mmouse_move\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_mouse_event)\n",
      "File \u001b[0;32m~/miniconda3/envs/reinforcement_project/lib/python3.13/site-packages/vispy/app/canvas.py:173\u001b[0m, in \u001b[0;36mCanvas.__init__\u001b[0;34m(self, title, size, position, show, autoswap, app, create_native, vsync, resizable, decorate, fullscreen, config, shared, keys, parent, dpi, always_on_top, px_scale, backend_kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Get app instance\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m app \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_app \u001b[38;5;241m=\u001b[39m \u001b[43muse_app\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_reuse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(app, Application):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_app \u001b[38;5;241m=\u001b[39m app\n",
      "File \u001b[0;32m~/miniconda3/envs/reinforcement_project/lib/python3.13/site-packages/vispy/app/_default_app.py:47\u001b[0m, in \u001b[0;36muse_app\u001b[0;34m(backend_name, call_reuse)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m default_app  \u001b[38;5;66;03m# Current backend matches backend_name\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Create default app\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m default_app \u001b[38;5;241m=\u001b[39m \u001b[43mApplication\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m default_app\n",
      "File \u001b[0;32m~/miniconda3/envs/reinforcement_project/lib/python3.13/site-packages/vispy/app/application.py:47\u001b[0m, in \u001b[0;36mApplication.__init__\u001b[0;34m(self, backend_name)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_use\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reinforcement_project/lib/python3.13/site-packages/vispy/app/application.py:240\u001b[0m, in \u001b[0;36mApplication._use\u001b[0;34m(self, backend_name)\u001b[0m\n\u001b[1;32m    236\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not import backend \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    237\u001b[0m        \u001b[38;5;241m%\u001b[39m (name, \u001b[38;5;28mstr\u001b[39m(mod\u001b[38;5;241m.\u001b[39mwhy_not)))\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m try_others:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# Fail if user wanted to use a specific backend\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m imported_toolkits:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m# Warn if were unable to use an already imported toolkit\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlthough \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is already imported, the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m backend \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    244\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcould not\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mbe used (\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m). \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote that running \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    245\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultiple GUI toolkits simultaneously can cause \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    246\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mside effects.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    247\u001b[0m            (native_module_name, name, \u001b[38;5;28mstr\u001b[39m(mod\u001b[38;5;241m.\u001b[39mwhy_not)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not import backend \"jupyter_rfb\":\nThe jupyter_rfb backend relies on a the jupyter_rfb library: ``pip install jupyter_rfb``"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# X. Advanced 3D Graph Visualization with VisPy & NetworkX\n",
    "# ---------------------------------------------------------------------------\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "from vispy import scene\n",
    "from vispy.scene import visuals\n",
    "from vispy.color import Color, ColorArray\n",
    "\n",
    "log.info(\"\\n--- Attempting 3D Graph Visualization with VisPy ---\")\n",
    "\n",
    "# --- Data Subsetting for Visualization (same as previous examples) ---\n",
    "N_USERS_FOR_VIS = 15\n",
    "N_ASSETS_PER_USER_HISTORY_FOR_VIS = 5\n",
    "N_SIMILAR_ASSETS_FOR_VIS = 3\n",
    "N_RECOMMENDATIONS_TO_HIGHLIGHT = 2 # For a sample user, highlight N recommendations\n",
    "\n",
    "if utility_matrix_df.empty or item_similarity_df.empty:\n",
    "    log.warning(\"VisPy: Utility matrix or item similarity matrix is empty. Cannot create graph.\")\n",
    "else:\n",
    "    sample_user_id_for_explanation_vp = None\n",
    "    explained_recommendations_vp = []\n",
    "    if len(utility_matrix_df.index) > 0:\n",
    "        user_interaction_counts_vp = utility_matrix_df.sum(axis=1).sort_values(ascending=False)\n",
    "        if not user_interaction_counts_vp.empty:\n",
    "            potential_sample_users_vp = user_interaction_counts_vp.head(min(N_USERS_FOR_VIS * 2, len(user_interaction_counts_vp))).index\n",
    "            sample_user_id_for_explanation_vp = np.random.choice(potential_sample_users_vp)\n",
    "            log.info(f\"VisPy: Sample user for explanation: {sample_user_id_for_explanation_vp}\")\n",
    "            explained_recommendations_vp = get_item_based_recommendations(\n",
    "                sample_user_id_for_explanation_vp, utility_matrix_df, item_similarity_df,\n",
    "                k_similar_items=5, n_recommendations=N_RECOMMENDATIONS_TO_HIGHLIGHT\n",
    "            )\n",
    "            log.info(f\"VisPy: Recommendations for {sample_user_id_for_explanation_vp} to explain: {explained_recommendations_vp}\")\n",
    "    else:\n",
    "        log.warning(\"VisPy: No users in utility matrix.\")\n",
    "\n",
    "    # --- Build the NetworkX Graph (same logic, different variable names) ---\n",
    "    G_vis_vp = nx.Graph()\n",
    "    nodes_to_add_vp_set = set() # Using a set to store (node_id, type) tuples to avoid duplicates\n",
    "    edges_to_add_vp_list = [] # List of edge dicts\n",
    "\n",
    "    # (Logic for populating nodes_to_add_vp_set and edges_to_add_vp_list is identical to the PyVista example,\n",
    "    #  just ensure you use the _vp suffixed variables if running both examples in the same notebook)\n",
    "\n",
    "    # 1. Add the sample user and their historical items\n",
    "    if sample_user_id_for_explanation_vp and sample_user_id_for_explanation_vp in utility_matrix_df.index:\n",
    "        nodes_to_add_vp_set.add((sample_user_id_for_explanation_vp, 'sample_user'))\n",
    "        user_hist_interactions_vp = utility_matrix_df.loc[sample_user_id_for_explanation_vp]\n",
    "        user_hist_items_vp = user_hist_interactions_vp[user_hist_interactions_vp > 0].sort_values(ascending=False).head(N_ASSETS_PER_USER_HISTORY_FOR_VIS).index.tolist()\n",
    "        for hist_item_isin in user_hist_items_vp:\n",
    "            nodes_to_add_vp_set.add((hist_item_isin, 'hist_asset'))\n",
    "            edges_to_add_vp_list.append({'source': sample_user_id_for_explanation_vp, 'target': hist_item_isin, 'type': 'bought', 'weight': user_hist_interactions_vp[hist_item_isin]})\n",
    "            if hist_item_isin in item_similarity_df.index:\n",
    "                similar_items_vp = item_similarity_df[hist_item_isin].sort_values(ascending=False).iloc[1:N_SIMILAR_ASSETS_FOR_VIS+1]\n",
    "                for similar_isin, sim_score in similar_items_vp.items():\n",
    "                    is_explained_rec = similar_isin in explained_recommendations_vp\n",
    "                    asset_type_label = 'explained_rec_source' if is_explained_rec else 'similar_asset'\n",
    "                    if similar_isin not in [item[0] for item in nodes_to_add_vp_set if item[1] == 'hist_asset']:\n",
    "                         nodes_to_add_vp_set.add((similar_isin, asset_type_label))\n",
    "                    edges_to_add_vp_list.append({'source': hist_item_isin, 'target': similar_isin, 'type': 'similar_to', 'weight': sim_score})\n",
    "                    if is_explained_rec:\n",
    "                        edges_to_add_vp_list.append({'source': sample_user_id_for_explanation_vp, 'target': similar_isin, 'type': 'recommended_because_similar', 'weight': sim_score})\n",
    "\n",
    "    # Add other context users and their assets (simplified for brevity)\n",
    "    other_user_ids_vp = [uid for uid in utility_matrix_df.index if uid != sample_user_id_for_explanation_vp]\n",
    "    context_user_ids_vp = np.random.choice(other_user_ids_vp, min(N_USERS_FOR_VIS -1, len(other_user_ids_vp)), replace=False) if other_user_ids_vp else []\n",
    "    for user_id in context_user_ids_vp:\n",
    "        nodes_to_add_vp_set.add((user_id, 'context_user'))\n",
    "        # ... (add their items and edges as in previous example) ...\n",
    "\n",
    "\n",
    "    # --- Populate NetworkX Graph and get positions ---\n",
    "    node_id_list_vp = [] # Keep an ordered list of node IDs for VisPy\n",
    "    node_attributes_vp = {} # Store attributes for VisPy\n",
    "\n",
    "    vispy_color_map = { # VisPy expects RGBA arrays (0-1 float or 0-255 int)\n",
    "        'sample_user': Color('green').rgba, 'hist_asset': Color('orange').rgba,\n",
    "        'similar_asset': Color('coral').rgba, 'explained_rec_source': Color('yellow').rgba,\n",
    "        'context_user': Color('lightblue').rgba, 'context_asset': Color('silver').rgba\n",
    "    }\n",
    "    vispy_size_map = { # Relative sizes\n",
    "        'sample_user': 15.0, 'hist_asset': 10.0, 'similar_asset': 8.0, 'explained_rec_source': 12.0,\n",
    "        'context_user': 7.0, 'context_asset': 6.0\n",
    "    }\n",
    "\n",
    "    for node_id, node_type in nodes_to_add_vp_set:\n",
    "        G_vis_vp.add_node(node_id)\n",
    "        node_id_list_vp.append(node_id)\n",
    "        node_attributes_vp[node_id] = {\n",
    "            'type': node_type,\n",
    "            'color': vispy_color_map.get(node_type, Color('gray').rgba),\n",
    "            'size': vispy_size_map.get(node_type, 5.0),\n",
    "            'label': f\"{node_type.replace('_',' ').title()}: {node_id}\" # For potential hover/picking\n",
    "        }\n",
    "    \n",
    "    edge_connect_list_vp = [] # List of (idx1, idx2) for edges\n",
    "    edge_colors_vp = []\n",
    "    vispy_edge_colors = {'bought': Color('darkgreen', alpha=0.5).rgba, 'similar_to': Color('darkred', alpha=0.7).rgba,\n",
    "                         'recommended_because_similar': Color('gold', alpha=0.9).rgba, 'bought_by_context': Color('dimgray', alpha=0.3).rgba}\n",
    "\n",
    "    # Map node IDs to their index in node_id_list_vp for edge connectivity\n",
    "    node_to_idx_map_vp = {node_id: i for i, node_id in enumerate(node_id_list_vp)}\n",
    "\n",
    "    for edge_info in edges_to_add_vp_list:\n",
    "        source_id, target_id = edge_info['source'], edge_info['target']\n",
    "        if source_id in node_to_idx_map_vp and target_id in node_to_idx_map_vp: # Ensure both nodes are in our visualized set\n",
    "            G_vis_vp.add_edge(source_id, target_id, type=edge_info['type'], weight=edge_info['weight'])\n",
    "            edge_connect_list_vp.append((node_to_idx_map_vp[source_id], node_to_idx_map_vp[target_id]))\n",
    "            edge_colors_vp.append(vispy_edge_colors.get(edge_info['type'], Color('lightgray', alpha=0.5).rgba))\n",
    "\n",
    "\n",
    "    if G_vis_vp.number_of_nodes() == 0:\n",
    "        log.warning(\"VisPy: Graph for visualization is empty. Skipping VisPy vis.\")\n",
    "    else:\n",
    "        log.info(f\"VisPy: NetworkX graph created: {G_vis_vp.number_of_nodes()} nodes, {len(edge_connect_list_vp)} edges for vis.\")\n",
    "        try:\n",
    "            pos_3d_vp_dict = nx.spring_layout(G_vis_vp, dim=3, seed=42, k=0.9/np.sqrt(G_vis_vp.number_of_nodes()), iterations=60)\n",
    "            # Convert dict of positions to NumPy array ordered by node_id_list_vp\n",
    "            node_pos_array_vp = np.array([pos_3d_vp_dict[node_id] for node_id in node_id_list_vp])\n",
    "            log.info(\"VisPy: 3D layout calculated.\")\n",
    "        except Exception as e_layout_vp:\n",
    "            log.error(f\"VisPy: Error calculating 3D layout: {e_layout_vp}. Skipping 3D plot.\")\n",
    "            node_pos_array_vp = None\n",
    "\n",
    "        if node_pos_array_vp is not None:\n",
    "            # --- Create VisPy Scene ---\n",
    "            canvas = scene.SceneCanvas(keys='interactive', show=True, bgcolor='white', size=(800,600))\n",
    "            view = canvas.central_widget.add_view()\n",
    "            \n",
    "            # Camera\n",
    "            view.camera = 'turntable' # Or 'arcball', 'fly', 'panzoom'\n",
    "            view.camera.fov = 45\n",
    "            view.camera.distance = np.max(np.ptp(node_pos_array_vp, axis=0)) * 2.5 # Auto-distance based on point cloud spread\n",
    "\n",
    "            # Prepare node data for VisPy\n",
    "            node_colors_array_vp = ColorArray([node_attributes_vp[node_id]['color'] for node_id in node_id_list_vp])\n",
    "            node_sizes_array_vp = np.array([node_attributes_vp[node_id]['size'] for node_id in node_id_list_vp])\n",
    "\n",
    "            # 1. Add Nodes (Markers visual)\n",
    "            nodes_vis = visuals.Markers()\n",
    "            nodes_vis.set_data(node_pos_array_vp, \n",
    "                               face_color=node_colors_array_vp, \n",
    "                               edge_color=None, # Can add edge_color for borders\n",
    "                               size=node_sizes_array_vp,\n",
    "                               scaling=True) # If True, size is in screen space, if False, in data space\n",
    "            view.add(nodes_vis)\n",
    "\n",
    "            # 2. Add Edges (Line visual)\n",
    "            if edge_connect_list_vp: # Only if there are edges\n",
    "                edge_pos_flat_vp = node_pos_array_vp[np.array(edge_connect_list_vp).flatten()]\n",
    "                # Reshape to (N_edges, 2, 3) for segmented lines, or use connect='segments'\n",
    "                \n",
    "                lines_vis = visuals.Line(pos=node_pos_array_vp, # All node positions\n",
    "                                         connect=np.array(edge_connect_list_vp), # Connectivity array\n",
    "                                         color=ColorArray(edge_colors_vp) if edge_colors_vp else 'gray', \n",
    "                                         width=2, # Can be an array too for variable widths\n",
    "                                         method='gl') # 'agg' is anti-aliased but can be slower\n",
    "                view.add(lines_vis)\n",
    "\n",
    "            # Add a 3D axis\n",
    "            visuals.XYZAxis(parent=view.scene)\n",
    "            \n",
    "            # To make it run in Jupyter, you might need to start VisPy's Qt event loop\n",
    "            # For standalone scripts, canvas.app.run() is used.\n",
    "            # In Jupyter, just showing the canvas might be enough or you might need:\n",
    "            # from vispy.app import use_app\n",
    "            # app = use_app() # Get or create an app instance\n",
    "            # app.run() # This might block if not handled correctly in a notebook\n",
    "            log.info(\"VisPy canvas created. If it doesn't show or is not interactive, backend/event loop might need adjustment for Jupyter.\")\n",
    "            \n",
    "            # For interactivity (hover/click) with VisPy, it's more involved.\n",
    "            # You'd typically subclass scene.visuals.Markers and override on_mouse_press/on_mouse_move,\n",
    "            # then perform picking calculations (e.g., ray casting or checking distance to points).\n",
    "            # This is significantly more complex than Plotly's or PyVista's built-in picking.\n",
    "            # For \"showing why a recommendation was given\", you'd need this custom interaction.\n",
    "\n",
    "            # Example of a simple mouse move event to print camera state (for debugging interaction)\n",
    "            # @canvas.events.mouse_move.connect\n",
    "            # def on_mouse_move(event):\n",
    "            #     # print(f\"Camera distance: {view.camera.distance}, center: {view.camera.center}\")\n",
    "            #     pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinforcement_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
